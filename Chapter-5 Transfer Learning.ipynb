{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfer learning** is a research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.\n",
    "\n",
    "In computer vision this means that we can use many open sourced deep learning models which were trained on a huge amounts of images and took a lot of time to train. \n",
    "\n",
    "Tensorflow makes it very easy to use powerful CV models and tailor them to your specific problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign language data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sign_language_project/pictures/amer_sign2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The American Sign Language letter database of hand gestures represent a multi-class problem with 24 classes of letters (excluding J and Z which require motion). \n",
    "\n",
    "The original dataset is obtain from here: \n",
    "\n",
    "https://www.kaggle.com/datamunge/sign-language-mnist \n",
    "\n",
    "The images are in a .csv file where the first element of a row is the label and the rest are the pixel values. The original image dimensions are 28x28x1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 28, 28)\n",
      "(27455,)\n",
      "(7172, 28, 28)\n",
      "(7172,)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy \n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def get_data(filename: str):\n",
    "    \"\"\"\n",
    "    A function to read the data given a filename\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    with open(filename) as csvfile:\n",
    "        for i, row in enumerate(csvfile):\n",
    "            # Skipping the header\n",
    "            if i > 0:\n",
    "                all_val = row.split(',')\n",
    "\n",
    "                label = int(all_val[0])\n",
    "                pixels = np.asarray(all_val[1:]).astype(float).reshape(28, 28)\n",
    "\n",
    "                labels.append(label)\n",
    "                images.append(pixels)\n",
    "    \n",
    "    # Converting to arrays\n",
    "    images = np.asarray(images)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "path_sign_mnist_train = f\"{os.getcwd()}/sign_language_project/data/sign_mnist_train.csv\"\n",
    "path_sign_mnist_test = f\"{os.getcwd()}/sign_language_project/data/sign_mnist_test.csv\"\n",
    "training_images, training_labels = get_data(path_sign_mnist_train)\n",
    "testing_images, testing_labels = get_data(path_sign_mnist_test)\n",
    "\n",
    "# Dimensions of data\n",
    "print(training_images.shape)\n",
    "print(training_labels.shape)\n",
    "print(testing_images.shape)\n",
    "print(testing_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 27455 training images and 7172 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# The bellow code loads the model architecture\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# Downloading the weights\n",
    "# The include_top=False indicates that we will using our custom input layer\n",
    "model = ResNet50(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177\n"
     ]
    }
   ],
   "source": [
    "# Number of layers\n",
    "print(len(model.layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is huge, containing 177 layers and millions of unique weights. One thing to note is that the input dimensions for the model are 224x224x3.\n",
    "\n",
    "The model outputs probabilities regarding 1000 classes. This will not be the case for our data thus we will freeze the top n layers of the model, add some custom layers at the bottom of the model and train it with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfering learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We first need to decide which layer to "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-tf",
   "language": "python",
   "name": "deep-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
