{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello world of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick overview of a simple feedforward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network is a type of machine learning algorythm which models itself after the human brain, creating an artificial neural network that allows the computer to learn by incorporating new data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Picture of a neural network](pictures/NN_schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each circle in the above diagram is called a **neuron**. \n",
    "\n",
    "Each neuron has an **activation function**.\n",
    "\n",
    "Most of the basic neural networks have an **input layer**, at least one **hidden layer** and and **output layer**. \n",
    "\n",
    "The arrows in the above diagram are called **connections**. Each connection provides the output of one neuron as an input to another neuron. Each connection is assigned a **weight** that represents its relative importance.\n",
    "\n",
    "Given an input, the network **forward propagates** the data via all the network and makes a prediction of $\\hat{y}$ and an error is calculated, for example, $E:=(y - \\hat{y})^{2}$. Then, during **backpropogation**, all the weights of the network are readjusted in such a way that the connections that had the biggest impact to the error are diminished. \n",
    "\n",
    "One iteration of feedforward and backpropogation is called an **epoch**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of resources that explain every bolded term. I will assume that the reader has at least an intuitive understanding of the concepts of deep learning and focus more on the implementation of neural networks in tensorflow and keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow (**tf** for short) is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications. \n",
    "\n",
    "As the name suggests, tensorflow deal with the *flow* of *tensors*. The flow represents the forward and back propogations and tensors are data represented as tensors.\n",
    "\n",
    "Throughout every notebook, I will be using tensorflow version **2.0.0**. \n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "To summarize, one can view the relationship between tensorflow and keras as tensorflow beeing used for deep calculations in the computer backend and keras is an API to query the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we see the numbers [0, 1, 2, 3, 4, 5] and [-1, 1, 3, 5, 7, 9]. If I asked you to come up with a rule that links the first list of numbers with the second, how would you do it? Maybe you would look at the 0 and -1 pair and start your deduction from there. Then you would analyze the pair of 1 and 1 and so on. \n",
    "\n",
    "The rule is that the second list of numbers are made by multiplying the first list numbers and subtracting one. The process of thinking of the rule, iterating through all the numbers in your head, going back and forth and seeing how good does your rule fit the data is a very similar process what a deep learning algorythm does. \n",
    "\n",
    "I will create a single layered neural network to solve this issue. As it turns out, to get good results, a very simple neural network is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definition:\n",
    "\n",
    "$$y:= f(x) = x * 2 - 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definition in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x) -> float: \n",
    "    \"\"\"\n",
    "    A simple function\n",
    "    \"\"\"\n",
    "    return x * 2 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating points in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [0, 1, 2, 3, 4, 5]\n",
    "ys = [f(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [0, 1, 2, 3, 4, 5]   f(x): [-1, 1, 3, 5, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"x: {xs}   f(x): {ys}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(xs, ys)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a neural network with tensorflow and keras in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above neural network will have one input neuron and one hidden layer. \n",
    "\n",
    "**tf.keras.Sequantial** initiates a sequantial model, which is just a simple feedfoward fully connected neural network. \n",
    "\n",
    "**keras.layer.Dense** creates a layer of neurons (just one in this case) with a precoded input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term 'sgd' stands for stochastic gradient descent. The loss function is \n",
    "$$loss(y, \\hat{y}) =  \\dfrac{1}{n} \\sum (y - \\hat{y})^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will wrap everything into a function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_f(xs, ys, epochs):\n",
    "    \"\"\"\n",
    "    A method to train a neural network\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "    model.fit(xs, ys, epochs=epochs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 0s 53ms/sample - loss: 23.3988\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 15.2906\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 10.0653\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 995us/sample - loss: 6.6970\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 4.5248\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 3.1232\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 2.2179\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.6324\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 1.2528\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 996us/sample - loss: 1.0059\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.8446\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 829us/sample - loss: 0.7383\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 1ms/sample - loss: 0.6676\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.6198\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.5867\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 999us/sample - loss: 0.5633\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 830us/sample - loss: 0.5459\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.5326\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.5219\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.5129\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.5050\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4979\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4913\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4850\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.4790\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.4731\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4674\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.4618\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4563\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4509\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4456\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4403\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4351\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4300\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4249\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4199\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4149\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4101\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.4052\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.4004\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3957\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3911\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3865\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3819\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.3774\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 836us/sample - loss: 0.3729\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3686\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3642\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3599\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3557\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3515\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3473\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3433\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3392\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3352\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3313\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3274\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3235\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3197\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.3159\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3122\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.3085\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3049\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.3013\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2977\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2942\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2908\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2873\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2840\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.2806\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2773\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2740\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.2708\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2676\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2645\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2613\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2583\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2552\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2522\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2492\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2463\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2434\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2405\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2377\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2349\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2321\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2294\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2267\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2240\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2214\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2188\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2162\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 998us/sample - loss: 0.2136\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2111\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2086\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.2062\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2037\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 831us/sample - loss: 0.2013\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.1990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 997us/sample - loss: 0.1966\n"
     ]
    }
   ],
   "source": [
    "model = approx_f(xs, ys, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After each epoch we can see the loss function's value. In general, this value should decrease with every epoch. If the value is not decreasing that means that either we are starting to overfit, something is wrong with the model specifications or the X values are not suitable to explain the Y values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.460748], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([6])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the true value of the function with x=6 is close to the predicted value of our neural network. By increasing the number of epochs, we can achieve better accuracy. The reader can play around with changing the number of epochs. At around 1 thousand epochs, the predicted value should be very very near 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-tf",
   "language": "python",
   "name": "deep-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
